{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleeper_wrapper import Stats, Players\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class StatsDF:\n",
    "    \"\"\"\n",
    "    Class to manage player stats for a specific season.\n",
    "    \"\"\"\n",
    "    def __init__(self, season_type: str = None, season_year: int = None):\n",
    "        self.season_type = season_type\n",
    "        self.season_year = season_year\n",
    "        self.stats = Stats()\n",
    "        self.players = Players()\n",
    "        self.players_df = None  # This will store the DataFrame with players\n",
    "        self.stats_df = None  # This will store the DataFrame with stats\n",
    "        self.all_stats = None  # This will store the merged DataFrame\n",
    "\n",
    "        self.selected_columns = [\n",
    "            'search_full_name','player_id', 'team', 'fantasy_positions', 'years_exp',\n",
    "            'active','age','height','weight','depth_chart_order'\n",
    "        ]\n",
    "\n",
    "        if season_year is not None and season_type is not None:\n",
    "            self.refresh_stats()\n",
    "\n",
    "    def refresh_stats(self):\n",
    "        \"\"\"\n",
    "        Get stats for the specified season type and year\n",
    "        and assign the DataFrame with players.\n",
    "        \"\"\"\n",
    "        self.stats_df = pd.DataFrame(self.stats.get_all_stats(self.season_type, self.season_year)).T\n",
    "        self.stats_df.index.name = \"player_id\"\n",
    "        self.players_df = self.get_players_df()\n",
    "        self.all_stats = self.merge_players_df()\n",
    "        self.all_stats = self.make_column_first('search_full_name')\n",
    "        self.convert_height_to_cm()  # Call the height conversion function here\n",
    "        self.convert_to_nan() # call the method to convert '' to nan\n",
    "\n",
    "    def convert_to_nan(self):\n",
    "        \"\"\"\n",
    "        Replace all empty strings with NaN in the entire DataFrame.\n",
    "        \"\"\"\n",
    "        self.all_stats.replace('', np.nan, inplace=True)\n",
    "\n",
    "    def get_players_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieve all players and filter selected columns.\n",
    "        \"\"\"\n",
    "        players_df = pd.DataFrame(self.players.get_all_players()).T\n",
    "        return players_df[self.selected_columns]\n",
    "\n",
    "    def merge_players_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Merge player stats and details.\n",
    "        \"\"\"\n",
    "        return pd.merge(self.stats_df, self.players_df, how='outer', on='player_id')\n",
    "\n",
    "    def get_stats_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return the DataFrame with stats.\n",
    "        \"\"\"\n",
    "        return self.stats_df\n",
    "\n",
    "    def display_stats_df(self) -> None:\n",
    "        \"\"\"\n",
    "        Display the first few rows of the DataFrame.\n",
    "        \"\"\"\n",
    "        print(self.all_stats.head())\n",
    "\n",
    "    def make_column_first(self, col_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Move specified column to the first position and sort the DataFrame by column.\n",
    "        \"\"\"\n",
    "        if col_name in self.all_stats.columns:\n",
    "            col_to_move = self.all_stats.pop(col_name)\n",
    "            self.all_stats.insert(0, col_name, col_to_move)\n",
    "            self.all_stats.sort_values(by=col_name, axis=0, inplace=True)\n",
    "        else:\n",
    "            print(f'Column \"{col_name}\" does not exist in the DataFrame.')\n",
    "        return self.all_stats\n",
    "    \n",
    "    def get_positions_df(self, player_position: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return the DataFrame with player positions.\n",
    "        \"\"\"\n",
    "        return self.all_stats[self.all_stats['fantasy_positions'].apply(lambda x: player_position in x if hasattr(x, '__iter__') else False)]\n",
    "        \n",
    "    def drop_empty_columns(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drop empty columns from the DataFrame.\n",
    "        \"\"\"\n",
    "        self.all_stats = self.all_stats.dropna(axis=1, how='all')\n",
    "        return self.all_stats\n",
    "        \n",
    "\n",
    "    def parse_height(self, height) -> float:\n",
    "        \"\"\"\n",
    "        Parse height string in the format 'X\\'Y\"' (e.g. '6\\'1\"') and convert to centimeters.\n",
    "        If the height is already a number (presumably in centimeters), just return that number.\n",
    "        If the height is not a string (e.g., it's a float or NaN), return None.\n",
    "        \"\"\"\n",
    "        if isinstance(height, str):\n",
    "            if '\\'' in height and '\"' in height:\n",
    "                parts = height.split('\\'')\n",
    "                if len(parts) == 2:  # Make sure parts contains two elements\n",
    "                    feet = int(parts[0])\n",
    "                    inches_part = parts[1]\n",
    "                    inches = int(inches_part.replace('\"', '')) if inches_part.replace('\"', '').isdigit() else 0\n",
    "                    return self.feet_to_inches(feet, inches)\n",
    "            elif height.isdigit():\n",
    "                return float(height)\n",
    "        return None\n",
    "\n",
    "    def export_to_csv(self):\n",
    "        df = self.get_stats_df()\n",
    "        df.to_csv('stats.csv')\n",
    "\n",
    "    @staticmethod\n",
    "    def feet_to_inches(feet, inches):\n",
    "        total_inches = feet * 12 + inches\n",
    "        return total_inches\n",
    "\n",
    "    def convert_height_to_cm(self):\n",
    "        \"\"\"\n",
    "        Convert height column from feet and inches to centimeters.\n",
    "        \"\"\"\n",
    "        self.all_stats['height'] = self.all_stats['height'].apply(self.parse_height)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_position(df, position: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame for a specific position.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    position (str): The position for which to preprocess the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The preprocessed DataFrame for the specified position.\n",
    "    \"\"\"\n",
    "    df = df.get_positions_df(position)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.dropna(subset=['pos_rank_ppr'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_22 = StatsDF(\"regular\",2022)\n",
    "df_stats_21 = StatsDF(\"regular\",2021)\n",
    "df_stats_20 = StatsDF(\"regular\",2020)\n",
    "df_stats_19 = StatsDF(\"regular\",2019)\n",
    "df_stats_18 = StatsDF(\"regular\",2018)\n",
    "df_stats_17 = StatsDF(\"regular\",2017)\n",
    "df_stats_16 = StatsDF(\"regular\",2016)\n",
    "df_stats_15 = StatsDF(\"regular\",2015)\n",
    "df_stats_14 = StatsDF(\"regular\",2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_22.refresh_stats()\n",
    "df_stats_21.refresh_stats()\n",
    "df_stats_20.refresh_stats()\n",
    "df_stats_19.refresh_stats()\n",
    "df_stats_18.refresh_stats()\n",
    "df_stats_17.refresh_stats()\n",
    "df_stats_16.refresh_stats()\n",
    "df_stats_15.refresh_stats()\n",
    "df_stats_14.refresh_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.StatsDF at 0x1e545b15db0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming df_stats_22, df_stats_21, ..., df_stats_14 are your dataframes\n",
    "all_dataframes = [df_stats_22.all_stats, df_stats_21.all_stats, df_stats_20.all_stats,\n",
    "                  df_stats_19.all_stats, df_stats_18.all_stats, df_stats_17.all_stats,\n",
    "                  df_stats_16.all_stats, df_stats_15.all_stats, df_stats_14.all_stats]\n",
    "\n",
    "all_dataframes_wo_22= [df_stats_21.all_stats, df_stats_20.all_stats,\n",
    "                  df_stats_19.all_stats, df_stats_18.all_stats, df_stats_17.all_stats,\n",
    "                  df_stats_16.all_stats, df_stats_15.all_stats, df_stats_14.all_stats]\n",
    "\n",
    "all_dataframes_combined = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "all_dataframes_combined_wo_22 = pd.concat(all_dataframes_wo_22, ignore_index=True)\n",
    "\n",
    "# Now you have all the data from different years in one combined dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DB' 'LB' 'DL' 'QB' 'OG' 'OL' 'LS' 'WR' 'RB' 'TE' 'OT' None 'K' 'P' 'LEO'\n",
      " 'DEF' nan]\n"
     ]
    }
   ],
   "source": [
    "exploded_pos = all_dataframes_combined['fantasy_positions'].explode()\n",
    "unique_pos = exploded_pos.unique()\n",
    "print(unique_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions_df(dataframe, player_position: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return the DataFrame with player positions.\n",
    "    \"\"\"\n",
    "    return dataframe[dataframe['fantasy_positions'].apply(lambda x: player_position in x if hasattr(x, '__iter__') else False)]\n",
    "\n",
    "\n",
    "def drop_empty_columns(dataframe):\n",
    "\n",
    "    return dataframe.dropna(axis=1, how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qb_df = get_positions_df(all_dataframes_combined_wo_22, \"QB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_full_name</th>\n",
       "      <th>player_id</th>\n",
       "      <th>pass_inc</th>\n",
       "      <th>rec_yd</th>\n",
       "      <th>pts_ppr</th>\n",
       "      <th>rec_tgt</th>\n",
       "      <th>pr_yd</th>\n",
       "      <th>rec_td_lng</th>\n",
       "      <th>pass_yd</th>\n",
       "      <th>pr_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>punt_blkd</th>\n",
       "      <th>team</th>\n",
       "      <th>fantasy_positions</th>\n",
       "      <th>years_exp</th>\n",
       "      <th>active</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>depth_chart_order</th>\n",
       "      <th>snp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaronbailey</td>\n",
       "      <td>4683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>73.0</td>\n",
       "      <td>230</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aaronmurray</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>73.0</td>\n",
       "      <td>210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>aaronrodgers</td>\n",
       "      <td>96</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>334.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>adrianmartinez</td>\n",
       "      <td>11065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DET</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>74.0</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>aidanoconnell</td>\n",
       "      <td>10866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LV</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>75.0</td>\n",
       "      <td>210</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77616</th>\n",
       "      <td>zacdysert</td>\n",
       "      <td>1455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>75.0</td>\n",
       "      <td>221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77624</th>\n",
       "      <td>zachconque</td>\n",
       "      <td>4607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>78.0</td>\n",
       "      <td>237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77640</th>\n",
       "      <td>zachmettenberger</td>\n",
       "      <td>1935</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>77.0</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77654</th>\n",
       "      <td>zachterrell</td>\n",
       "      <td>4924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>73.0</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77663</th>\n",
       "      <td>zachwilson</td>\n",
       "      <td>7538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>[QB]</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3040 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       search_full_name player_id  pass_inc  rec_yd  pts_ppr  rec_tgt  pr_yd   \n",
       "2           aaronbailey      4683       NaN     NaN      NaN      NaN    NaN  \\\n",
       "26          aaronmurray      2019       NaN     NaN      NaN      NaN    NaN   \n",
       "33         aaronrodgers        96     165.0    -4.0   334.30      1.0    NaN   \n",
       "101      adrianmartinez     11065       NaN     NaN      NaN      NaN    NaN   \n",
       "117       aidanoconnell     10866       NaN     NaN      NaN      NaN    NaN   \n",
       "...                 ...       ...       ...     ...      ...      ...    ...   \n",
       "77616         zacdysert      1455       NaN     NaN      NaN      NaN    NaN   \n",
       "77624        zachconque      4607       NaN     NaN      NaN      NaN    NaN   \n",
       "77640  zachmettenberger      1935      72.0     NaN    73.88      NaN    NaN   \n",
       "77654       zachterrell      4924       NaN     NaN      NaN      NaN    NaN   \n",
       "77663        zachwilson      7538       NaN     NaN      NaN      NaN    NaN   \n",
       "\n",
       "       rec_td_lng  pass_yd  pr_lng  ...  punt_blkd  team  fantasy_positions   \n",
       "2             NaN      NaN     NaN  ...        NaN   BAL               [QB]  \\\n",
       "26            NaN      NaN     NaN  ...        NaN  None               [QB]   \n",
       "33            NaN   4115.0     NaN  ...        NaN   NYJ               [QB]   \n",
       "101           NaN      NaN     NaN  ...        NaN   DET               [QB]   \n",
       "117           NaN      NaN     NaN  ...        NaN    LV               [QB]   \n",
       "...           ...      ...     ...  ...        ...   ...                ...   \n",
       "77616         NaN      NaN     NaN  ...        NaN  None               [QB]   \n",
       "77624         NaN      NaN     NaN  ...        NaN  None               [QB]   \n",
       "77640         NaN   1412.0     NaN  ...        NaN  None               [QB]   \n",
       "77654         NaN      NaN     NaN  ...        NaN   BAL               [QB]   \n",
       "77663         NaN      NaN     NaN  ...        NaN   NYJ               [QB]   \n",
       "\n",
       "       years_exp  active   age  height  weight  depth_chart_order    snp  \n",
       "2              1    True  None    73.0     230                4.0    NaN  \n",
       "26             6   False    29    73.0     210                NaN    NaN  \n",
       "33            18    True    39    74.0     223                1.0    NaN  \n",
       "101            0    True    23    74.0     220                NaN    NaN  \n",
       "117            0    True    24    75.0     210                3.0    NaN  \n",
       "...          ...     ...   ...     ...     ...                ...    ...  \n",
       "77616          9   False    31    75.0     221                NaN    NaN  \n",
       "77624          5    True    27    78.0     237                NaN    NaN  \n",
       "77640          6   False    29    77.0     224                NaN  313.0  \n",
       "77654          1    True    24    73.0     206                NaN    NaN  \n",
       "77663          2    True    24    74.0     214                2.0    NaN  \n",
       "\n",
       "[3040 rows x 119 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##all_rb_df = get_positions_df(all_dataframes_combined, \"RB\")\n",
    "#all_wr_df = get_positions_df(all_dataframes_combined, \"WR\")\n",
    "#all_K_df = get_positions_df(all_dataframes_combined, \"K\")\n",
    "#all_def_df = get_positions_df(all_dataframes_combined, \"DEF\")\n",
    "#all_te_df = get_positions_df(all_dataframes_combined, \"TE\")\n",
    "drop_empty_columns(all_qb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qb_df.to_csv(\"2014_22-all_qb_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, threshold=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.features_to_keep = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Impute missing values\n",
    "        self.imputer = KNNImputer(n_neighbors=5)\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "\n",
    "        # Fit a model to get feature importances\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_imputed, y)\n",
    "\n",
    "        # Get feature importances\n",
    "        importances = rf.feature_importances_\n",
    "\n",
    "        # Select features with importances above the threshold\n",
    "        self.features_to_keep = X.columns[importances > self.threshold]\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Impute missing values\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "\n",
    "        # Filter features based on feature importance\n",
    "        X_filtered = pd.DataFrame(X_imputed, columns=X.columns)[self.features_to_keep]\n",
    "\n",
    "        # Create a scaler object\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit and transform the features\n",
    "        X_scaled = scaler.fit_transform(X_filtered)\n",
    "\n",
    "        return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bcurl\\AppData\\Local\\Temp\\ipykernel_30288\\415343227.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by='player_id', inplace=True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 255 but corresponding boolean dimension is 112",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m     feature_names \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39mfeatures_to_keep\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m features_processed, target, feature_names, df\n\u001b[1;32m---> 31\u001b[0m features_processed, target, feature_names, clean_all_qb_df \u001b[39m=\u001b[39m preprocess_data(all_qb_df)\n",
      "Cell \u001b[1;32mIn[28], line 24\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df, target_col, threshold, inplace)\u001b[0m\n\u001b[0;32m     21\u001b[0m features \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39mcols_to_drop)\n\u001b[0;32m     23\u001b[0m preprocessor \u001b[39m=\u001b[39m Preprocessor(threshold)\n\u001b[1;32m---> 24\u001b[0m preprocessor\u001b[39m.\u001b[39;49mfit(features, target)\n\u001b[0;32m     25\u001b[0m features_processed \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39mtransform(features)\n\u001b[0;32m     27\u001b[0m feature_names \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39mfeatures_to_keep\u001b[39m.\u001b[39mtolist()\n",
      "Cell \u001b[1;32mIn[23], line 39\u001b[0m, in \u001b[0;36mPreprocessor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     36\u001b[0m importances \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mfeature_importances_\n\u001b[0;32m     38\u001b[0m \u001b[39m# Select features with importances above the threshold\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_to_keep \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mcolumns[importances \u001b[39m>\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold]\n",
      "File \u001b[1;32mc:\\Users\\bcurl\\anaconda3\\envs\\aienv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5195\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5192\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5193\u001b[0m         key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m-> 5195\u001b[0m result \u001b[39m=\u001b[39m getitem(key)\n\u001b[0;32m   5196\u001b[0m \u001b[39m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5197\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 255 but corresponding boolean dimension is 112"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df, target_col='pos_rank_ppr', threshold=0.01, inplace=False):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame and return the features and target arrays.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    target_col (str): The column name of the target variable in df.\n",
    "    threshold (float): The minimum feature importance for a feature to be kept.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the preprocessed features array and the target array.\n",
    "    \"\"\"\n",
    "    cols_to_drop = [\"search_full_name\",\"rank_ppr\",\"pos_rank_ppr\",\"pos_rank_half_ppr\",\n",
    "    \"rank_std\",\"rank_half_ppr\",\"pos_rank_std\",\"team\",\"fantasy_positions\",\"player_id\",]\n",
    "    \n",
    "    df.sort_values(by='player_id', inplace=True)\n",
    "    \n",
    "    target = df[target_col]\n",
    "    target = target.fillna(0)\n",
    "    # Exclude target column from features\n",
    "    features = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    preprocessor = Preprocessor(threshold)\n",
    "    preprocessor.fit(features, target)\n",
    "    features_processed = preprocessor.transform(features)\n",
    "\n",
    "    feature_names = preprocessor.features_to_keep.tolist()\n",
    "\n",
    "    return features_processed, target, feature_names, df\n",
    "\n",
    "features_processed, target, feature_names, clean_all_qb_df = preprocess_data(all_qb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
