{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_22 = StatsDF(\"regular\",2022)\n",
    "df_stats_21 = StatsDF(\"regular\",2021)\n",
    "#df_stats_20 = StatsDF(\"regular\",2020)\n",
    "#df_stats_19 = StatsDF(\"regular\",2019)\n",
    "#df_stats_18 = StatsDF(\"regular\",2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleeper_wrapper import Stats, Players\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class StatsDF:\n",
    "    \"\"\"\n",
    "    Class to manage player stats for a specific season.\n",
    "    \"\"\"\n",
    "    def __init__(self, season_type: str = None, season_year: int = None):\n",
    "        self.season_type = season_type\n",
    "        self.season_year = season_year\n",
    "        self.stats = Stats()\n",
    "        self.players = Players()\n",
    "        self.players_df = None  # This will store the DataFrame with players\n",
    "        self.stats_df = None  # This will store the DataFrame with stats\n",
    "        self.all_stats = None  # This will store the merged DataFrame\n",
    "\n",
    "        self.selected_columns = [\n",
    "            'search_full_name','player_id', 'team', 'fantasy_positions', 'years_exp',\n",
    "            'active','age','height','weight','depth_chart_order'\n",
    "        ]\n",
    "\n",
    "        if season_year is not None and season_type is not None:\n",
    "            self.refresh_stats()\n",
    "\n",
    "    def refresh_stats(self):\n",
    "        \"\"\"\n",
    "        Get stats for the specified season type and year\n",
    "        and assign the DataFrame with players.\n",
    "        \"\"\"\n",
    "        self.stats_df = pd.DataFrame(self.stats.get_all_stats(self.season_type, self.season_year)).T\n",
    "        self.stats_df.index.name = \"player_id\"\n",
    "        self.players_df = self.get_players_df()\n",
    "        self.all_stats = self.merge_players_df()\n",
    "        self.all_stats = self.make_column_first('search_full_name')\n",
    "        self.convert_height_to_cm()  # Call the height conversion function here\n",
    "        self.convert_to_nan() # call the method to convert '' to nan\n",
    "\n",
    "    def convert_to_nan(self):\n",
    "        \"\"\"\n",
    "        Replace all empty strings with NaN in the entire DataFrame.\n",
    "        \"\"\"\n",
    "        self.all_stats.replace('', np.nan, inplace=True)\n",
    "\n",
    "    def get_players_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieve all players and filter selected columns.\n",
    "        \"\"\"\n",
    "        players_df = pd.DataFrame(self.players.get_all_players()).T\n",
    "        return players_df[self.selected_columns]\n",
    "\n",
    "    def merge_players_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Merge player stats and details.\n",
    "        \"\"\"\n",
    "        return pd.merge(self.stats_df, self.players_df, how='outer', on='player_id')\n",
    "\n",
    "    def get_stats_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return the DataFrame with stats.\n",
    "        \"\"\"\n",
    "        return self.stats_df\n",
    "\n",
    "    def display_stats_df(self) -> None:\n",
    "        \"\"\"\n",
    "        Display the first few rows of the DataFrame.\n",
    "        \"\"\"\n",
    "        print(self.all_stats.head())\n",
    "\n",
    "    def make_column_first(self, col_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Move specified column to the first position and sort the DataFrame by column.\n",
    "        \"\"\"\n",
    "        if col_name in self.all_stats.columns:\n",
    "            col_to_move = self.all_stats.pop(col_name)\n",
    "            self.all_stats.insert(0, col_name, col_to_move)\n",
    "            self.all_stats.sort_values(by=col_name, axis=0, inplace=True)\n",
    "        else:\n",
    "            print(f'Column \"{col_name}\" does not exist in the DataFrame.')\n",
    "        return self.all_stats\n",
    "    \n",
    "    def get_positions_df(self, player_position: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return the DataFrame with player positions.\n",
    "        \"\"\"\n",
    "        return self.all_stats[self.all_stats['fantasy_positions'].apply(lambda x: player_position in x if hasattr(x, '__iter__') else False)]\n",
    "        \n",
    "    def drop_empty_columns(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drop empty columns from the DataFrame.\n",
    "        \"\"\"\n",
    "        self.all_stats = self.all_stats.dropna(axis=1, how='all')\n",
    "        return self.all_stats\n",
    "        \n",
    "\n",
    "    def parse_height(self, height) -> float:\n",
    "        \"\"\"\n",
    "        Parse height string in the format 'X\\'Y\"' (e.g. '6\\'1\"') and convert to centimeters.\n",
    "        If the height is already a number (presumably in centimeters), just return that number.\n",
    "        If the height is not a string (e.g., it's a float or NaN), return None.\n",
    "        \"\"\"\n",
    "        if isinstance(height, str):\n",
    "            if '\\'' in height and '\"' in height:\n",
    "                parts = height.split('\\'')\n",
    "                if len(parts) == 2:  # Make sure parts contains two elements\n",
    "                    feet = int(parts[0])\n",
    "                    inches_part = parts[1]\n",
    "                    inches = int(inches_part.replace('\"', '')) if inches_part.replace('\"', '').isdigit() else 0\n",
    "                    return self.feet_to_inches(feet, inches)\n",
    "            elif height.isdigit():\n",
    "                return float(height)\n",
    "        return None\n",
    "\n",
    "    def export_to_csv(self):\n",
    "        df = self.get_stats_df()\n",
    "        df.to_csv('stats.csv')\n",
    "\n",
    "    @staticmethod\n",
    "    def feet_to_inches(feet, inches):\n",
    "        total_inches = feet * 12 + inches\n",
    "        return total_inches\n",
    "\n",
    "    def convert_height_to_cm(self):\n",
    "        \"\"\"\n",
    "        Convert height column from feet and inches to centimeters.\n",
    "        \"\"\"\n",
    "        self.all_stats['height'] = self.all_stats['height'].apply(self.parse_height)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, threshold=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.features_to_keep = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Impute missing values\n",
    "        self.imputer = KNNImputer(n_neighbors=5)\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "\n",
    "        # Fit a model to get feature importances\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_imputed, y)\n",
    "\n",
    "        # Get feature importances\n",
    "        importances = rf.feature_importances_\n",
    "\n",
    "        # Select features with importances above the threshold\n",
    "        self.features_to_keep = X.columns[importances > self.threshold]\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Impute missing values\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "\n",
    "        # Filter features based on feature importance\n",
    "        X_filtered = pd.DataFrame(X_imputed, columns=X.columns)[self.features_to_keep]\n",
    "\n",
    "        # Create a scaler object\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit and transform the features\n",
    "        X_scaled = scaler.fit_transform(X_filtered)\n",
    "\n",
    "        return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_position(df, position: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame for a specific position.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    position (str): The position for which to preprocess the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The preprocessed DataFrame for the specified position.\n",
    "    \"\"\"\n",
    "    df = df.get_positions_df(position)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.dropna(subset=['pos_rank_ppr'])\n",
    "    return df\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def preprocess_data(df, target_col='pos_rank_ppr', threshold=0.01, inplace=False):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame and return the features and target arrays.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    target_col (str): The column name of the target variable in df.\n",
    "    threshold (float): The minimum feature importance for a feature to be kept.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the preprocessed features array and the target array.\n",
    "    \"\"\"\n",
    "    cols_to_drop = [\"search_full_name\",\"rank_ppr\",\"pos_rank_ppr\",\"pos_rank_half_ppr\",\n",
    "    \"rank_std\",\"rank_half_ppr\",\"pos_rank_std\",\"team\",\"fantasy_positions\",\"player_id\",]\n",
    "    \n",
    "    df.sort_values(by='player_id', inplace=True)\n",
    "    \n",
    "    target = df[target_col]\n",
    "\n",
    "    # Exclude target column from features\n",
    "    features = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    preprocessor = Preprocessor(threshold)\n",
    "    preprocessor.fit(features, target)\n",
    "    features_processed = preprocessor.transform(features)\n",
    "\n",
    "    feature_names = preprocessor.features_to_keep.tolist()\n",
    "\n",
    "    return features_processed, target, feature_names, df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def yearly_pos_rank_model(features_imputed_knn, target, feature_names):\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features_imputed_knn, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    predictions = model.predict(features_test)\n",
    "    mse = mean_squared_error(target_test, predictions)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]  # Sort feature importances in descending order\n",
    "    names = [feature_names[i] for i in indices]  # Rearrange feature names so they match the sorted feature importances\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for i in range(features_train.shape[1]):\n",
    "        print(f\"{i+1}. Feature {names[i]} ({importances[indices[i]]})\")\n",
    "\n",
    "    return model, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def drop_features_not_in_other_dataset(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Drop features from arr1 that are not present in arr2.\n",
    "\n",
    "    Parameters:\n",
    "    arr1 (np.ndarray): First NumPy array.\n",
    "    arr2 (np.ndarray): Second NumPy array.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: NumPy array with features not in arr2 dropped.\n",
    "    \"\"\"\n",
    "    columns_to_drop = set(arr1[0]) - set(arr2[0])\n",
    "    indices_to_keep = [i for i, col in enumerate(arr1[0]) if col not in columns_to_drop]\n",
    "    return arr1[:, indices_to_keep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb_stats_22 = preprocess_position(df_stats_22, \"QB\")\n",
    "qb_features_22 , qb_target_22 ,features_22, proc_qb_stats_22= preprocess_data(qb_stats_22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb_22_pred = qb_model_21.predict(qb_features_22)\n",
    "\n",
    "# Create a DataFrame from the features\n",
    "# Create a DataFrame from the features\n",
    "player_prediction_22 = proc_qb_stats_22.copy()\n",
    "\n",
    "# Add the predictions as a new column\n",
    "player_prediction_22['predicted_rank'] = qb_22_pred\n",
    "\n",
    "# Fill missing predictions with 0\n",
    "player_prediction_22['predicted_rank'] = player_prediction_22['predicted_rank'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_prediction_22.to_csv('player_prediction_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb_stats_21 = preprocess_position(df_stats_21, \"QB\")\n",
    "qb_features_21, qb_target_21,features_21, proc_qb_stats_21 = preprocess_data(qb_stats_21)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_model_21 , qb_mse_21= yearly_pos_rank_model(qb_features_21, qb_target_21, features_21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qb_mse_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb_stats_20 = preprocess_position(df_stats_20, \"QB\")\n",
    "qb_features_20, qb_target_20 = preprocess_data(qb_stats_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb_stats_19 = preprocess_position(df_stats_19, \"QB\")\n",
    "qb_features_19, qb_target_19 , qb_feature_names_19= preprocess_data(qb_stats_19,\"QB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb_stats_18 = preprocess_position(df_stats_18, \"QB\")\n",
    "\n",
    "qb_features_18, qb_target_18, qb_feature_names_18 = preprocess_data(qb_stats_18,\"QB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_model_18 , qb_mse_18 = yearly_pos_rank_model(qb_features_18, qb_target_18, qb_feature_names_18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_stats_19.sort_values(by='player_id', inplace=True)\n",
    "qb_19_pred = qb_model_18.predict(qb_features_19)\n",
    "\n",
    "# Create a DataFrame from the features\n",
    "# Create a DataFrame from the features\n",
    "player_predictions = qb_stats_19.copy()\n",
    "\n",
    "# Add the predictions as a new column\n",
    "player_predictions['predicted_rank'] = qb_19_pred\n",
    "\n",
    "# Fill missing predictions with 0\n",
    "player_predictions['predicted_rank'] = player_predictions['predicted_rank'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_features_20 = drop_features_not_in_other_dataset(qb_features_20, qb_features_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_stats_19.sort_values(by='player_id', inplace=True)\n",
    "qb_19_pred = qb_model_18.predict(qb_features_19)\n",
    "\n",
    "# Create a DataFrame from the features\n",
    "# Create a DataFrame from the features\n",
    "player_predictions = qb_stats_19.copy()\n",
    "\n",
    "# Add the predictions as a new column\n",
    "player_predictions['predicted_rank'] = qb_19_pred\n",
    "\n",
    "# Fill missing predictions with 0\n",
    "player_predictions['predicted_rank'] = player_predictions['predicted_rank'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_predictions.to_csv(\"player_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the averaged data, you would first need to calculate the averages over 5-year periods\n",
    "df_average = qb_stats_21.groupby(['player_id', qb_stats_21['year'] // 5]).mean().reset_index()\n",
    "\n",
    "# Split into features and target\n",
    "features_avg = df_average.drop('rank', axis=1)\n",
    "target_avg = df_average['rank']\n",
    "\n",
    "# Split into training and test datasets\n",
    "features_train_avg, features_test_avg, target_train_avg, target_test_avg = train_test_split(features_avg, target_avg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and fit the model on 5-year averaged data\n",
    "model_average_years = RandomForestRegressor()\n",
    "model_average_years.fit(features_train_avg, target_train_avg)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions_average_years = model_average_years.predict(features_test_avg)\n",
    "mse_average_years = mean_squared_error(target_test_avg, predictions_average_years)\n",
    "print(f\"5-year average MSE: {mse_average_years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted predictions\n",
    "weights = [mse_average_years / (mse_individual_years + mse_average_years), \n",
    "           mse_individual_years / (mse_individual_years + mse_average_years)]\n",
    "predictions_weighted = weights[0] * predictions_individual_years + weights[1] * predictions_average_years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume last_year_data is a DataFrame holding all your players' data from the last year.\n",
    "\n",
    "\n",
    "# Don't forget to apply the same preprocessing to this new data as you did to the training data.\n",
    "# This might involve cleaning the data, dealing with missing values, encoding categorical variables, etc.\n",
    "\n",
    "# Predict the player ranks for next year\n",
    "next_year_pred = model.predict(last_year_data)\n",
    "\n",
    "# Create a DataFrame to hold the player names and their predicted ranks\n",
    "player_predictions = pd.DataFrame({\n",
    "    'player_name': last_year_data['player_name'],\n",
    "    'predicted_rank': next_year_pred\n",
    "})\n",
    "\n",
    "# Sort players by their predicted rank\n",
    "player_predictions = player_predictions.sort_values('predicted_rank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.threshold = threshold\n",
    "        self.features_to_keep = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Impute missing values\n",
    "        self.imputer = KNNImputer(n_neighbors=5)\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "\n",
    "        # Fit a model to get feature importances\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_imputed, y)\n",
    "\n",
    "        # Get feature importances\n",
    "        importances = rf.feature_importances_\n",
    "\n",
    "        # Select features with importances above the threshold\n",
    "        self.features_to_keep = X.columns[importances > self.threshold]\n",
    "\n",
    "        # Create a scaler object and fit it\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(X[self.features_to_keep])\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Impute missing values\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "\n",
    "        # Filter features based on feature importance\n",
    "        X_filtered = pd.DataFrame(X_imputed, columns=X.columns)[self.features_to_keep]\n",
    "\n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.transform(X_filtered)\n",
    "\n",
    "        return X_scaled\n",
    "\n",
    "\n",
    "def preprocess_data(df, target_col='pos_rank_ppr', threshold=0.001, preprocessor=None, training_features=None):\n",
    "    cols_to_drop = [\"search_full_name\",\"rank_ppr\",\"pos_rank_ppr\",\"pos_rank_half_ppr\",\n",
    "                    \"rank_std\",\"rank_half_ppr\",\"pos_rank_std\",\"team\",\"fantasy_positions\",\"player_id\"]\n",
    "\n",
    "    df = df.sort_values(by='player_id').copy()\n",
    "\n",
    "    target = df[target_col]\n",
    "    features = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # If this is not the initial training data, there should be a list of training features available\n",
    "    if training_features is not None:\n",
    "        # Get missing columns in the test set\n",
    "        missing_cols = set(training_features) - set(features.columns)\n",
    "        # Add a missing column in test set with default value equal to 0\n",
    "        for c in missing_cols:\n",
    "            features[c] = 0\n",
    "        # Remove any extra columns that are in the test set but not the training set\n",
    "        extra_cols = set(features.columns) - set(training_features)\n",
    "        features = features.drop(columns=list(extra_cols))\n",
    "        # Ensure the order of column in the test set is in the same order than in train set\n",
    "        features = features[training_features]\n",
    "    # If this is the initial training data, create the preprocessor and fit it\n",
    "    else:\n",
    "        preprocessor = Preprocessor(threshold)\n",
    "        preprocessor.fit(features, target)\n",
    "    \n",
    "    features_processed = preprocessor.transform(features)\n",
    "    feature_names = preprocessor.features_to_keep.tolist()\n",
    "\n",
    "    return features_processed, target, feature_names, preprocessor, df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def yearly_pos_rank_model(features_imputed_knn, target, feature_names):\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features_imputed_knn, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    predictions = model.predict(features_test)\n",
    "    mse = mean_squared_error(target_test, predictions)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]  # Sort feature importances in descending order\n",
    "    names = [feature_names[i] for i in indices]  # Rearrange feature names so they match the sorted feature importances\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for i in range(features_train.shape[1]):\n",
    "        print(f\"{i+1}. Feature {names[i]} ({importances[indices[i]]})\")\n",
    "\n",
    "    return model, mse, importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define the position you're interested in\n",
    "position = \"QB\"\n",
    "\n",
    "# Preprocess your training data\n",
    "df_train = preprocess_position(df_stats_21, position)\n",
    "features_train, target_train, feature_names_train, preprocessor, df_train = preprocess_data(df_train)\n",
    "# Fit your model\n",
    "model, mse, importances = yearly_pos_rank_model(features_train, target_train, feature_names_train)\n",
    "print(f\"Training completed. MSE: {mse}\")\n",
    "\n",
    "# Now, let's suppose you have a new DataFrame called df_stats_22 for the year 2022 that you want to make predictions on\n",
    "df_test = preprocess_position(df_stats_22, position)\n",
    "\n",
    "# Before making predictions, you need to preprocess your test data in the same way you preprocessed your training data\n",
    "features_test, target_test, feature_names_test, _, df_test = preprocess_data(df_test, preprocessor=preprocessor, training_features=feature_names_train)\n",
    "\n",
    "# Now you can make predictions\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "# And calculate the mean absolute error\n",
    "mae = mean_absolute_error(target_test, predictions)\n",
    "print(f\"MAE on test set: {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
